{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4860cad-9d67-496e-9351-d8db78f334f6",
   "metadata": {},
   "source": [
    "# Découverte de la classification avec les arbres de décision\n",
    "\n",
    "Lino Galiana  \n",
    "2025-12-26\n",
    "\n",
    "<div class=\"badge-container\"><div class=\"badge-text\">Pour essayer les exemples présents dans ce tutoriel :</div><a href=\"https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/modelisation/2_classification.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/static/v1?logo=github&label=&message=View%20on%20GitHub&color=181717\" alt=\"View on GitHub\"></a>\n",
    "<a href=\"https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=true&name=«2_classification»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-vscode.sh»&init.personalInitArgs=«modelisation%202_classification»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://custom-icon-badges.demolab.com/badge/SSP%20Cloud-Lancer_avec_VSCode-blue?logo=vsc&logoColor=white\" alt=\"Onyxia\"></a>\n",
    "<a href=\"https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&name=«2_classification»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-jupyter.sh»&init.personalInitArgs=«modelisation%202_classification»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/SSP%20Cloud-Lancer_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"></a>\n",
    "<a href=\"https://colab.research.google.com/github/linogaliana/python-datascientist-notebooks-colab//blob/main//notebooks/modelisation/2_classification.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a><br></div>\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "Ce chapitre vise à présenter de manière très succincte le principe de l’entraînement de modèles dans un cadre de classification. L’objectif est d’illustrer la démarche à partir d’un algorithme dont le principe est assez intuitif. Il s’agit d’illustrer quelques uns des concepts évoqués dans les chapitres précédents, notamment ceux relatifs à l’entraînement d’un modèle. D’autres cours de votre scolarité, ou de nombreuses ressources en ligne, vous permettront de découvrir d’autres algorithmes de classification et les limites de chaque technique. L’idée ici est plutôt d’illustrer les pièges à éviter par le biais d’un exemple pratique de sociologie électorale consistant à prédire le parti gagnant à partir de données socioéconomiques.\n",
    "\n",
    "## 1.1 Données\n",
    "\n",
    "L’ensemble de la partie *machine learning* utilise le même jeu de données, présenté dans l’[introduction de cette partie](index.qmd) : les données de vote aux élections présidentielles américaines croisées à des variables sociodémographiques. Le code est disponible [sur Github](https://github.com/linogaliana/python-datascientist/blob/main/content/modelisation/get_data.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f366f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas openpyxl plotnine plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42220fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/linogaliana/python-datascientist/main/content/modelisation/get_data.py'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('getdata.py', 'wb').write(r.content)\n",
    "\n",
    "import getdata\n",
    "votes = getdata.create_votes_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088fc866-293c-41e5-90ab-36c04d63d2fb",
   "metadata": {},
   "source": [
    "## 1.2 Approche méthodologique\n",
    "\n",
    "### 1.2.1 Principe des arbres de décision\n",
    "\n",
    "Comme cela a été évoqué dans les chapitres précédents, on adopte une approche d’apprentissage automatique quand on désire avoir des règles opérationnelles simples à mettre en oeuvre à des fins de décision. Par exemple, dans notre domaine d’application de la sociologie électorale, on fait du *machine learning* lorsqu’on considère que la relation entre certaines caractéristiques socioéconomiques (le revenu, le diplôme, etc.) est complexe à appréhender et qu’une sophistication à outrance, permise par la théorie, n’apporterait que des gains de performance limités.\n",
    "\n",
    "Nous allons illustrer l’approche traditionnelle à partir de méthodes de classification intuitives s’appuyant sur des arbres de décision. Cette approche est assez intuitive. Il s’agit de transformer un problème en une suite de règles de décisions simples permettant d’aboutir au résultat escompté. Par exemple,\n",
    "\n",
    "-   si le revenu est supérieur à 15000\\$/an\n",
    "-   et que l’âge est inférieur à 40 ans\n",
    "-   et que le niveau de diplôme est supérieur au bac\n",
    "\n",
    "alors statistiquement on aura plutôt un vote démocrate.\n",
    "\n",
    "La <a href=\"#fig-iris-classification-fr\" class=\"quarto-xref\">Figure 1.1</a> illustre, de manière graphique, la manière dont un arbre de décision est construit comme une suite de choix binaires. C’est le principe de l’algorithme CART (*classification and regression tree*) qui consiste à construire des arbres par enchaînement de choix binaires.\n",
    "\n",
    "<figure id=\"fig-iris-classification-fr\">\n",
    "<img src=\"https://scikit-learn.org/stable/_images/iris.svg\" />\n",
    "<figcaption>Figure 1.1: Exemple d’arbre de décision sur le jeu de données classique iris. Source: <a href=\"https://scikit-learn.org/stable/modules/tree.html\">Documentation de scikit-learn</a></figcaption>\n",
    "</figure>\n",
    "\n",
    "Dans cette situation, on voit qu’une première règle de décision parfaite permet de déterminer la classe *setosa*. Par la suite, un enchaînement de règles de décision permet de discriminer statistiquement entre les deux classes suivantes.\n",
    "\n",
    "### 1.2.2 Le fonctionnement itératif\n",
    "\n",
    "Cette structure finale est le résultat d’un algorithme itératif. Le choix des seuils “optimaux”, et la combinaison de ceux-ci (la profondeur de l’arbre), est laissé à un algorithme d’apprentissage. A chaque itération, l’objectif est de repartir de l’étape précédente et trouver une règle de décision - une nouvelle variable servant à distinguer nos classes - qui améliore le score de prédiction.\n",
    "\n",
    "Techniquement cela se fait par le biais de mesure d’impureté, c’est-à-dire d’homogénéité des noeuds (les groupes issus des critères de décision). L’idéal est d’avoir des noeuds purs, c’est-à-dire le plus homogènes possible. Les plus utilisées sont l’indice de Gini ou l’entropie de Shannon.\n",
    "\n",
    "> **Note**\n",
    ">\n",
    "> <div class=\"callout callout-style-default callout-note callout-titled\">\n",
    "> <div class=\"callout-header d-flex align-content-center\">\n",
    "> <div class=\"callout-icon-container\">\n",
    "> <i class=\"callout-icon\"></i>\n",
    "> </div>\n",
    "> <div class=\"callout-title-container flex-fill\">\n",
    "> Note\n",
    "> </div>\n",
    "> </div>\n",
    "> <div class=\"callout-body-container callout-body\">\n",
    ">\n",
    "> Il serait bien sûr possible de présenter ces intuitions par la formalisation mathématique. Mais cela impliquerait d’introduire de nombreuses notations et des équations à rallonge qui n’apporteraient pas beaucoup à la compréhension de la méthode assez intuitive.\n",
    ">\n",
    "> Je laisse les lecteurs curieux rechercher les équations derrière les concepts évoqués sur cette page.\n",
    ">\n",
    "> </div>\n",
    "> </div>\n",
    "\n",
    "Ces mesures d’impureté servent à guider le choix de la structure de l’arbre, notamment de sa racine (le point de départ) à sa feuille (le noeud auquel on aboutit après avoir enchaîné le chemin de combinaison d’arbre).\n",
    "\n",
    "Plutôt que de partir d’une page blanche, tester des règles jusqu’à en trouver quelques unes fonctionnant bien, on part en général d’un ensemble trop large de règles qu’on élague (*prune* en Anglais) progressivement. Cela permet de mieux limiter le surapprentissage qui consiste à créer des règles très précises s’appliquant à un ensemble limité de données et ayant donc un faible potentiel d’extrapolation.\n",
    "\n",
    "Par exemple, si on reprend la <a href=\"#fig-iris-classification-fr\" class=\"quarto-xref\">Figure 1.1</a>, on voit que certains noeuds s’appliquent à un ensemble très limité de données (des échantillons de trois ou quatre observations): le pouvoir statistique de ces règles est sans doute limité.\n",
    "\n",
    "# 2. Application\n",
    "\n",
    "Pour appliquer un modèle de classification, il nous faut\n",
    "trouver une variable dichotomique. Le choix naturel est\n",
    "de prendre la variable dichotomique qu’est la victoire ou\n",
    "défaite d’un des partis.\n",
    "\n",
    "Même si les Républicains ont perdu en 2020, ils l’ont emporté\n",
    "dans plus de comtés (moins peuplés). Nous allons considérer\n",
    "que la victoire des Républicains est notre *label* 1 et la défaite *0*.\n",
    "\n",
    "Nous allons utiliser les variables suivantes pour créer nos règles de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvars = [\n",
    "  'Unemployment_rate_2019', 'Median_Household_Income_2021',\n",
    "  'Percent of adults with less than a high school diploma, 2018-22',\n",
    "  \"Percent of adults with a bachelor's degree or higher, 2018-22\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5cac0-9c7c-423f-9fb5-9c95294a5dc1",
   "metadata": {},
   "source": [
    "Nous allons également utiliser ces packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get update && sudo apt-get install gridviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7a387-a1ce-421f-9703-7936bd7bba63",
   "metadata": {},
   "source": [
    "> **Tip**\n",
    ">\n",
    "> <div class=\"callout callout-style-default callout-tip callout-titled\">\n",
    "> <div class=\"callout-header d-flex align-content-center\">\n",
    "> <div class=\"callout-icon-container\">\n",
    "> <i class=\"callout-icon\"></i>\n",
    "> </div>\n",
    "> <div class=\"callout-title-container flex-fill\">\n",
    "> Exercice 1 : Premier algorithme de classification\n",
    "> </div>\n",
    "> </div>\n",
    "> <div class=\"callout-body-container callout-body\">\n",
    ">\n",
    "> 1.  Créer une variable *dummy* appelée `y` dont la valeur vaut 1 quand les républicains l’emportent.\n",
    "> 2.  En utilisant la fonction prête à l’emploi nommée `train_test_split` de la librairie `sklearn.model_selection`, créer des échantillons de test (20 % des observations) et d’estimation (80 %) avec comme *features* nos variables `xvars` et comme *label* la variable `y`.\n",
    "> 3.  Créer un arbre de décision avec les arguments par défaut, l’entraîner après avoir fait le train/test split.\n",
    "> 4.  Le visualiser avec la fonction `plot_tree`. Quel est le problème ?\n",
    "> 5.  Evaluer sa performance prédictive. Comparer à celle d’un arbre dont la profondeur est 4. Conclure.\n",
    "> 6.  Représenter l’arbre de profondeur 4 avec la fonction `export_graphviz`.\n",
    "> 7.  Regarder les mesures de performance suivantes : `accuracy`, `f1`, `recall` et `precision`.\n",
    ">     Représenter la matrice de confusion. Quel est le problème ? Quelle solution voyez-vous ?\n",
    "> 8.  \\[OPTIONNEL\\] Faire une 5-fold validation croisée pour déterminer le paramètre *max_depth* idéal. Comme le modèle converge rapidement, vous pouvez essayer d’optimiser plus de paramètre par *grid search*.\n",
    ">\n",
    "> </div>\n",
    "> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ab622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "votes['y'] = (votes['votes_gop'] > votes['votes_dem']).astype(int)\n",
    "\n",
    "df = votes.loc[:, [\"y\"] + xvars]\n",
    "df = df.dropna()\n",
    "\n",
    "# Question 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.loc[: , xvars],\n",
    "    df['y'], test_size=0.2, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48393d59-74d9-4d53-89e5-76f35bdcbfb3",
   "metadata": {},
   "source": [
    "Quand on définit un objet Scikit (un estimateur seul ou un *pipeline* enchaînant des étapes) on obtient ce type d’objet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f49e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 1\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "clf_default = tree.DecisionTreeClassifier()\n",
    "clf_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf90b3-ec97-462a-aaf8-d48838664eaa",
   "metadata": {},
   "source": [
    "L’arbre de décision représenté sur la <a href=\"#fig-decision-q4\" class=\"quarto-xref\">Figure 2.1</a> montre clairement que nous avons besoin d’élaguer celui-ci. Nous allons tester, de manière arbitraire, l’arbre de profondeur 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig-decision-q4",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 2\n",
    "plt.figure()\n",
    "tree.plot_tree(clf_default, filled=True)\n",
    "plt.title(\"Decision tree trained on US presidential elections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6df09c-34f2-4728-953d-dfb4d6d824d1",
   "metadata": {},
   "source": [
    "Si on compare les performances des deux modèles sur l’échantillon de test, on voit que le plus parcimonieux est légèrement meilleur. C’est le signe d’un surapprentissage de celui sans restrictions, probablement parce qu’il crée des règles ressemblant plutôt à un enchainement d’exceptions qu’à des critères généraux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca71978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"model\": ['No restriction', 'max_depth = 4'],\n",
    "        \"performance\": [clf_default.score(X_test, y_test), clf.score(X_test, y_test)]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6902f5e-b374-4c76-9734-18e09bbb60ba",
   "metadata": {},
   "source": [
    "Si on représente notre arbre de décision favori, on voit que le chemin de la racine à la feuille se comprend maintenant beaucoup mieux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig-decision-q6",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 6\n",
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(\n",
    "  clf, out_file=None,\n",
    "  feature_names=X_train.columns,\n",
    "  class_names = ['lose', 'win'],\n",
    "  filled=True, rounded=True,\n",
    "  special_characters=True\n",
    ")\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "sc_accuracy = sklearn.metrics.accuracy_score(y_pred, y_test)\n",
    "sc_f1 = sklearn.metrics.f1_score(y_pred, y_test)\n",
    "sc_recall = sklearn.metrics.recall_score(y_pred, y_test)\n",
    "sc_precision = sklearn.metrics.precision_score(y_pred, y_test)\n",
    "\n",
    "stats_perf = pd.DataFrame.from_dict(\n",
    "  {\n",
    "    \"Accuracy\": [sc_accuracy], \"Recall\": [sc_recall],\n",
    "    \"Precision\": [sc_precision], \"F1\": [sc_f1]\n",
    "  }, orient = \"index\", columns = [\"Score\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622f914-6581-4187-b504-678743846b73",
   "metadata": {},
   "source": [
    "Maintenant, si on représente la matrice de confusion, on voit que notre modèle n’est pas trop mauvais au global mais tend à sur-prédire la classe 1 (victoire des Républicains). Pourquoi fait-il ça ? Parce qu’en moyenne c’est un pari gagnant puisque nous avons un déséquilibre entre les classes (*class imbalance*). Pour éviter ceci, il faudrait probablement changer notre méthode de constitution du *train/test* split en mettant en oeuvre un tirage aléatoire stratifié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig-decision-q7",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Question 7\n",
    "predictions = clf.predict(X_test)\n",
    "cm = sklearn.metrics.confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(\n",
    "  confusion_matrix=cm,\n",
    "  display_labels=clf.classes_\n",
    ")\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa88a8a-ea4f-403f-a436-e210337ef3e1",
   "metadata": {},
   "source": [
    "Avec la validation croisée, on parvient à encore améliorer les performances prédictives de notre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8fed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = df.loc[: , xvars]\n",
    "y = df['y']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [2, 3, 4, 5, 8, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53aea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "params_cols = [\"param_max_depth\", \"param_min_samples_leaf\", \"param_min_samples_split\", \"param_criterion\"]\n",
    "\n",
    "table = results[\n",
    "    params_cols + [\"mean_test_score\", \"std_test_score\", \"rank_test_score\"]\n",
    "].sort_values(\"rank_test_score\")\n",
    "\n",
    "table.sort_values(\"mean_test_score\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95022a8c-e2f7-481d-9307-9ae3be440dd1",
   "metadata": {},
   "source": [
    "Cela nous permet de voir que nous n’étions pas si loin du paramètre optimal en prenant de manière arbitraire `max_depth=4`. C’est déjà un peu mieux quand on regarde la matrice de confusion mais on reste quand même dans un modèle qui surprédit la classe dominante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig-decision-confusionCV",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions, labels=best_model.classes_)\n",
    "disp = metrics.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=best_model.classes_\n",
    ")\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98c0f6-fbe6-4afb-ad1b-c6ae7da97311",
   "metadata": {},
   "source": [
    "Si on regarde l’arbre de décision (**?@fig-decision-treeCV**) que cela nous donne finalement, on peut en conclure que:\n",
    "\n",
    "1.  Les variables de diplôme puis celle de revenu permettent de mieux dissocier les classes\n",
    "2.  La variable de taux de chômage n’est que secondaire\n",
    "\n",
    "Pour aller plus loin il faudrait intégrer plus de variable dans le modèle. Mais comment faire sans risquer d’accroître le surapprentissage ? Ce sera l’objet du chapitre sur la sélection de variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-fig-decision-treeCV",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(\n",
    "  best_model, out_file=None,\n",
    "  feature_names=X.columns,\n",
    "  class_names = ['lose', 'win'],\n",
    "  filled=True, rounded=True,\n",
    "  special_characters=True\n",
    ")\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a9fdc-0ef6-4539-ade3-209e8d60130b",
   "metadata": {},
   "source": [
    "# 3. Conclusion\n",
    "\n",
    "Nous venons de voir rapidement la démarche générale quand on adopte le *machine learning*. Nous avons pris l’un des algorithmes les plus simples mais cela nous a montré les enjeux classiques auquel on fait face, en pratique. Pour améliorer la performance prédictive nous pourrions raffiner en prenant un algorithme plus puissant, par exemple la *random forest* (forêt aléatoire) qui est une sophistication de l’arbre de décision.\n",
    "\n",
    "Mais nous devrions surtout passer du temps à réfléchir à la structure de nos données ce qui explique que de bonnes modélisations viennent après de bonnes statistiques descriptives. Sans ces dernières nous naviguons à vue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/home/runner/work/python-datascientist/python-datascientist/.venv/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
